#!/bin/bash

# =============================================================================
# RAG Flask - Utilidades de Desarrollo
# =============================================================================
# Script con utilidades comunes para desarrollo y testing

set -e

echo "üõ†Ô∏è  RAG Flask - Dev Utils"
echo "========================"

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

print_status() { echo -e "${GREEN}‚úÖ $1${NC}"; }
print_warning() { echo -e "${YELLOW}‚ö†Ô∏è  $1${NC}"; }
print_error() { echo -e "${RED}‚ùå $1${NC}"; }
print_info() { echo -e "${BLUE}‚ÑπÔ∏è  $1${NC}"; }

# Check virtual environment
check_venv() {
    if [ ! -d "venv" ]; then
        print_error "Entorno virtual no encontrado. Ejecuta ./setup.sh primero"
        exit 1
    fi
    source venv/bin/activate
}

# Test API endpoints
test_api() {
    print_info "üîç Testeando endpoints de la API..."
    
    # Check if server is running
    if ! curl -s http://localhost:5000/health > /dev/null 2>&1; then
        print_error "Servidor no est√° ejecut√°ndose en puerto 5000"
        print_info "Inicia el servidor con ./start_local.sh o ./start_production.sh"
        exit 1
    fi
    
    echo ""
    print_info "üì° Probando endpoints:"
    
    # Test health endpoint
    echo -n "  ‚Ä¢ /health: "
    if curl -s http://localhost:5000/health | grep -q "healthy"; then
        echo -e "${GREEN}‚úÖ OK${NC}"
    else
        echo -e "${RED}‚ùå ERROR${NC}"
    fi
    
    # Test config endpoint
    echo -n "  ‚Ä¢ /config: "
    if curl -s http://localhost:5000/config > /dev/null; then
        echo -e "${GREEN}‚úÖ OK${NC}"
    else
        echo -e "${RED}‚ùå ERROR${NC}"
    fi
    
    # Test system-info endpoint
    echo -n "  ‚Ä¢ /system-info: "
    if curl -s http://localhost:5000/system-info > /dev/null; then
        echo -e "${GREEN}‚úÖ OK${NC}"
    else
        echo -e "${RED}‚ùå ERROR${NC}"
    fi
    
    # Test query endpoint with sample query
    echo -n "  ‚Ä¢ /query (POST): "
    QUERY_RESULT=$(curl -s -X POST http://localhost:5000/query \
        -H "Content-Type: application/json" \
        -d '{"query": "test query", "max_results": 1}' 2>/dev/null)
    
    if echo "$QUERY_RESULT" | grep -q "answer\|documents"; then
        echo -e "${GREEN}‚úÖ OK${NC}"
    else
        echo -e "${RED}‚ùå ERROR${NC}"
    fi
    
    echo ""
    print_status "Testing de API completado"
}

# Debug system status
debug_system() {
    print_info "üîß Debug del sistema..."
    
    echo ""
    print_info "üìä Estado del sistema:"
    
    # Check Python environment
    echo "  ‚Ä¢ Python: $(python --version 2>&1)"
    echo "  ‚Ä¢ Virtual env: ${VIRTUAL_ENV:-"No activo"}"
    
    # Check required modules
    echo ""
    print_info "üì¶ M√≥dulos principales:"
    
    for module in flask langchain faiss openai; do
        echo -n "  ‚Ä¢ $module: "
        if python -c "import $module; print('‚úÖ OK')" 2>/dev/null; then
            true  # Already printed by Python
        else
            echo -e "${RED}‚ùå FALTA${NC}"
        fi
    done
    
    # Check project modules
    echo ""
    print_info "üèóÔ∏è  M√≥dulos del proyecto:"
    
    for module in preprocessing model_providers rag_chain evaluation; do
        echo -n "  ‚Ä¢ $module: "
        if python -c "import $module; print('‚úÖ OK')" 2>/dev/null; then
            true
        else
            echo -e "${RED}‚ùå ERROR${NC}"
        fi
    done
    
    # Check configuration
    echo ""
    print_info "‚öôÔ∏è  Configuraci√≥n:"
    
    if [ -f ".env" ]; then
        source .env
        echo "  ‚Ä¢ Archivo .env: ‚úÖ Encontrado"
        echo "  ‚Ä¢ LLM Provider: ${LLM_PROVIDER:-"No configurado"}"
        echo "  ‚Ä¢ Embedding Provider: ${EMBEDDING_PROVIDER:-"No configurado"}"
        if [ -n "$OPENAI_API_KEY" ] && [ "$OPENAI_API_KEY" != "sk-your-openai-api-key-here" ]; then
            echo "  ‚Ä¢ OpenAI API Key: ‚úÖ Configurada"
        else
            echo "  ‚Ä¢ OpenAI API Key: ‚ùå No configurada"
        fi
    else
        echo "  ‚Ä¢ Archivo .env: ‚ùå No encontrado"
    fi
    
    # Check index
    echo ""
    print_info "üóÇÔ∏è  √çndice vectorial:"
    
    if [ -f "vector_store/index.faiss" ]; then
        echo "  ‚Ä¢ Archivo √≠ndice: ‚úÖ Encontrado"
        echo "  ‚Ä¢ Tama√±o: $(du -sh vector_store/index.faiss | cut -f1)"
    else
        echo "  ‚Ä¢ Archivo √≠ndice: ‚ùå No encontrado"
    fi
    
    if [ -f "index_metadata.json" ]; then
        echo "  ‚Ä¢ Metadatos: ‚úÖ Encontrados"
        python -c "
import json
with open('index_metadata.json', 'r') as f:
    meta = json.load(f)
print(f'  ‚Ä¢ Total chunks: {meta.get(\"total_chunks\", \"N/A\")}')
print(f'  ‚Ä¢ Modelo usado: {meta.get(\"embedding_model\", \"N/A\")}')
" 2>/dev/null || echo "  ‚Ä¢ Error leyendo metadatos"
    else
        echo "  ‚Ä¢ Metadatos: ‚ùå No encontrados"
    fi
}

# Quick test with sample query
quick_test() {
    print_info "‚ö° Test r√°pido del sistema..."
    
    check_venv
    
    # Test model loading
    python -c "
from model_providers import get_embeddings_model, get_llm_model
from rag_chain import create_rag_chain

print('üîç Probando modelo de embeddings...')
embed_model = get_embeddings_model()
test_embedding = embed_model.embed_query('test query')
print(f'‚úÖ Embedding generado: {len(test_embedding)} dimensiones')

print('ü§ñ Probando modelo LLM...')
llm_model = get_llm_model()
print('‚úÖ Modelo LLM cargado')

print('üîó Probando cadena RAG...')
rag_chain = create_rag_chain()
print('‚úÖ Cadena RAG creada')

print('üìù Realizando consulta de prueba...')
try:
    result = rag_chain.invoke({
        'question': '¬øQu√© es un certificado de antecedentes?'
    })
    print(f'‚úÖ Consulta exitosa: {len(result.get(\"answer\", \"\"))} caracteres de respuesta')
except Exception as e:
    print(f'‚ö†Ô∏è  Advertencia en consulta: {e}')
    
print('üéâ Test r√°pido completado')
"
    
    if [ $? -eq 0 ]; then
        print_status "Test r√°pido exitoso"
    else
        print_error "Errores en test r√°pido"
        exit 1
    fi
}

# Benchmark performance
benchmark() {
    print_info "üìä Benchmark de rendimiento..."
    
    check_venv
    
    cat > benchmark_test.py << 'EOF'
import time
import statistics
from model_providers import get_embeddings_model, get_llm_model
from rag_chain import create_rag_chain

def benchmark_embeddings(model, queries, iterations=3):
    """Benchmark embedding generation"""
    times = []
    
    for query in queries:
        query_times = []
        for _ in range(iterations):
            start = time.time()
            model.embed_query(query)
            end = time.time()
            query_times.append(end - start)
        times.extend(query_times)
    
    return {
        'avg': statistics.mean(times),
        'min': min(times),
        'max': max(times),
        'std': statistics.stdev(times) if len(times) > 1 else 0
    }

def benchmark_rag_chain(chain, queries, iterations=2):
    """Benchmark RAG chain"""
    times = []
    
    for query in queries:
        for _ in range(iterations):
            start = time.time()
            try:
                chain.invoke({'question': query})
                end = time.time()
                times.append(end - start)
            except Exception as e:
                print(f'Error en query "{query}": {e}')
    
    return {
        'avg': statistics.mean(times) if times else 0,
        'min': min(times) if times else 0,
        'max': max(times) if times else 0,
        'std': statistics.stdev(times) if len(times) > 1 else 0
    }

# Test queries
test_queries = [
    "¬øQu√© documentos necesito?",
    "¬øCu√°les son los requisitos?",
    "¬øC√≥mo solicito un turno?",
    "¬øD√≥nde puedo hacer el tr√°mite?"
]

print("üöÄ Iniciando benchmark...")

# Benchmark embeddings
print("üîç Benchmark de embeddings...")
embed_model = get_embeddings_model()
embed_results = benchmark_embeddings(embed_model, test_queries)

print(f"  ‚Ä¢ Tiempo promedio: {embed_results['avg']:.3f}s")
print(f"  ‚Ä¢ Tiempo m√≠nimo: {embed_results['min']:.3f}s")
print(f"  ‚Ä¢ Tiempo m√°ximo: {embed_results['max']:.3f}s")
print(f"  ‚Ä¢ Desviaci√≥n est√°ndar: {embed_results['std']:.3f}s")

# Benchmark RAG chain
print("\nüîó Benchmark de cadena RAG...")
rag_chain = create_rag_chain()
rag_results = benchmark_rag_chain(rag_chain, test_queries)

print(f"  ‚Ä¢ Tiempo promedio: {rag_results['avg']:.3f}s")
print(f"  ‚Ä¢ Tiempo m√≠nimo: {rag_results['min']:.3f}s")
print(f"  ‚Ä¢ Tiempo m√°ximo: {rag_results['max']:.3f}s")
print(f"  ‚Ä¢ Desviaci√≥n est√°ndar: {rag_results['std']:.3f}s")

print("\nüìä Resumen de rendimiento:")
print(f"  ‚Ä¢ Embeddings por segundo: {1/embed_results['avg']:.1f}")
print(f"  ‚Ä¢ Consultas RAG por minuto: {60/rag_results['avg']:.1f}" if rag_results['avg'] > 0 else "  ‚Ä¢ Consultas RAG: Error")

print("\n‚úÖ Benchmark completado")
EOF
    
    python benchmark_test.py
    rm -f benchmark_test.py
    
    print_status "Benchmark completado"
}

# Show logs
show_logs() {
    print_info "üìã Mostrando logs del sistema..."
    
    if [ -d "logs" ]; then
        echo ""
        print_info "üìÅ Archivos de log disponibles:"
        ls -la logs/ 2>/dev/null || echo "No hay archivos de log"
        
        if [ -f "logs/app.log" ]; then
            echo ""
            print_info "üîç √öltimas 20 l√≠neas del log principal:"
            tail -20 logs/app.log
        fi
        
        if [ -f "logs/error.log" ]; then
            echo ""
            print_info "‚ùå √öltimas 10 l√≠neas del log de errores:"
            tail -10 logs/error.log
        fi
    else
        print_warning "Directorio logs no encontrado"
    fi
}

# Index documents
reindex() {
    print_info "üóÇÔ∏è  Re-indexando documentos..."
    
    check_venv
    
    if [ -f "vector_store/index.faiss" ]; then
        print_warning "‚ö†Ô∏è  Esto eliminar√° el √≠ndice actual"
        echo -n "¬øContinuar? (y/N): "
        read -r response
        if [[ ! "$response" =~ ^([yY][eE][sS]|[yY])$ ]]; then
            print_info "Re-indexaci√≥n cancelada"
            return
        fi
    fi
    
    python ingest.py
    
    if [ $? -eq 0 ]; then
        print_status "Re-indexaci√≥n completada"
    else
        print_error "Error en re-indexaci√≥n"
        exit 1
    fi
}

# Show help
show_help() {
    echo "RAG Flask - Utilidades de Desarrollo"
    echo ""
    echo "Uso: $0 <comando> [opciones]"
    echo ""
    echo "Comandos disponibles:"
    echo "  test-api           Probar endpoints de la API"
    echo "  debug              Mostrar estado del sistema"
    echo "  quick-test         Test r√°pido de funcionalidad"
    echo "  benchmark          Benchmark de rendimiento"
    echo "  logs               Mostrar logs del sistema"
    echo "  reindex            Re-indexar documentos"
    echo "  help               Mostrar esta ayuda"
    echo ""
    echo "Ejemplos:"
    echo "  $0 debug           # Ver estado del sistema"
    echo "  $0 test-api        # Probar que la API funcione"
    echo "  $0 quick-test      # Test r√°pido completo"
    echo "  $0 benchmark       # Medir rendimiento"
    echo ""
}

# Main function
main() {
    case "${1:-help}" in
        "test-api")
            test_api
            ;;
        "debug")
            check_venv
            debug_system
            ;;
        "quick-test")
            quick_test
            ;;
        "benchmark")
            benchmark
            ;;
        "logs")
            show_logs
            ;;
        "reindex")
            reindex
            ;;
        "help"|"--help"|"-h")
            show_help
            ;;
        *)
            print_error "Comando desconocido: $1"
            echo ""
            show_help
            exit 1
            ;;
    esac
}

# Run main function
main "$@" 